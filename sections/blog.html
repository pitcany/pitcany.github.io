<!-- Blog Section -->
<section class="d-block py-60" data-id="blog">
  <div class="container-lg">
    <div class="row gy-5">
      <div class="col-12">
        <div class="d-block block-heading text-center">
          <h3>Blog</h3>
        </div>
      </div>
    </div>
    <div class="row blog_slider">
      <!-- <div class="col-md-4 blog p-3">
        <a href="#" class="d-flex flex-column gap-2 blog-box">
          <div class="blog-img ofit">
            <img src="images/image.png" alt="image" />
          </div>
          <div class="d-flex flex-column gap-2 py-3 px-4 vclip">
            <h5>XAI</h5>
            <p>Coming Soon</p>
          </div>
        </a>
      </div> -->

      <div class="col-md-4 blog p-3">
        <!-- <a href="#" class="d-flex flex-column gap-2 blog-box"> -->
        <a data-id="blog1" class="d-flex flex-column gap-2 blog-box" onclick="openBlog(this)">
          <div class="blog-img ofit">
            <img src="images/image.png" alt="image" />
          </div>
          <div class="d-flex flex-column gap-2 py-3 px-4 vclip">
            <h5>Concentration Inequalities: Bounds on Random Variables</h5>
            <p>Concentration inequalities are powerful tools in probability theory and statistics for bounding the deviation of random variables from their expected values. They provide mathematical guarantees on how likely a random variable is to deviate significantly from its average behavior. In this blog post, we will explore different types of concentration inequalities, their underlying principles, provide proofs of the inequalities, and discuss their applications in analyzing the behavior of random variables.</p>
          </div>
        </a>
      </div>

      <div class="col-md-4 blog p-3">
        <!-- <a href="#" class="d-flex flex-column gap-2 blog-box"> -->
        <a data-id="blog2" class="d-flex flex-column gap-2 blog-box" onclick="openBlog(this)">
          <div class="blog-img ofit">
            <img src="images/image.png" alt="image" />
          </div>
          <div class="d-flex flex-column gap-2 py-3 px-4 vclip">
            <h5>Unraveling Patterns Over Time: An Introduction to Time Series Analysis</h5>
            <p>Time series analysis is a powerful tool for understanding and forecasting data that evolves over time. From stock prices and weather patterns to economic indicators and social media trends, time series data can provide valuable insights into underlying patterns and trends. In this blog post, we will explore the fundamentals of time series analysis, key concepts, and popular modeling techniques to help you make sense of time-dependent data.</p>
          </div>
        </a>
      </div>

      <div class="col-md-4 blog p-3">
        <a data-id="blog3" class="d-flex flex-column gap-2 blog-box" onclick="openBlog(this)">
          <div class="blog-img ofit">
            <img src="images/image.png" alt="image" />
          </div>
          <div class="d-flex flex-column gap-2 py-3 px-4 vclip">
            <h5>Biased Coin Simulation</h5>
            <p>
            A question I used to give in interviews was the following:
            </p>

            <p>
            I have a fair coin. How can I simulate a 1/3 probability of obtaining heads using a fair coin?
            </p>

            <p>
            Well today I'm going to discuss two solutions in detail.
            </p>
          </div>
        </a>
      </div>
    </div>
  </div>
</section>

<!-- Modal -->

<div class="modal fade" id="modal-blog1" tabindex="-1" aria-hidden="true"
>
  <div class="modal-dialog modal-dialog-scrollable">
    <div class="modal-content">
      <div class="modal-header">
        <h1 class="modal-title fs-5" id="staticBackdropLabel">
          Concentration Inequalities: Bounds on Random Variables
        </h1>
        <button
          type="button"
          class="btn-close"
          data-bs-dismiss="modal"
          aria-label="Close"
        ></button>
      </div>
      <div class="modal-body">
        <div class="d-flex flex-column gap-2">

        <p>Concentration inequalities are powerful tools in probability theory and statistics for bounding the deviation of random variables from their expected values. They provide mathematical guarantees on how likely a random variable is to deviate significantly from its average behavior. In this blog post, we will explore different types of concentration inequalities, their underlying principles, provide proofs of the inequalities, and discuss their applications in analyzing the behavior of random variables.</p>
        
        <h3>Introduction to Concentration Inequalities</h3>
        <p>Concentration inequalities provide bounds on the probability that a random variable deviates significantly from its mean or expected value. They measure the concentration or tightness of a distribution around its center. A tighter concentration implies less variability or dispersion in the values of the random variable.</p>
        
        <h3>Types of Concentration Inequalities</h3>
        <p>There are several well-known concentration inequalities, each with its own assumptions and properties:</p>
        
        <ul>
          <li><strong>Markov's Inequality:</strong> Markov's inequality bounds the probability that a non-negative random variable exceeds a certain threshold. For a non-negative random variable \(X\) and any \(t > 0\), Markov's inequality states that \(P(X \geq t) \leq \frac{{\mathbb{E}[X]}}{{t}}\).</li>
          
          <div class="proof">
            <h4>Proof:</h4>
            <p>Let \(X\) be a non-negative random variable and \(t > 0\). Using the definition of expectation, we have:</p>
            <p>\(\mathbb{E}[X] = \int_{0}^{\infty} x \cdot f(x) \, dx \geq \int_{t}^{\infty} x \cdot f(x) \, dx \geq \int_{t}^{\infty} t \cdot f(x) \, dx = t \cdot P(X \geq t)\).</p>
            <p>Dividing both sides by \(t\), we obtain \(P(X \geq t) \leq \frac{{\mathbb{E}[X]}}{{t}}\).</p>
          </div>
          
          <li><strong>Chebyshev's Inequality:</strong> Chebyshev's inequality provides a bound on the probability that a random variable deviates from its mean by a certain number of standard deviations. For any random variable \(X\) with finite variance \(\sigma^2\) and any \(k > 0\), Chebyshev's inequality states that \(P(|X - \mu| \geq k\sigma) \leq \frac{{1}}{{k^2}}\), where \(\mu\) is the mean and \(\sigma\) is the standard deviation of \(X\).</li>
          
          <div class="proof">
            <h4>Proof:</h4>
            <p>Let \(X\) be a random variable with mean \(\mu\) and variance \(\sigma^2\), and let \(k > 0\). Using the definition of variance, we have:</p>
            <p>\(\text{Var}(X) = \mathbb{E}[(X - \mu)^2] = \int_{-\infty}^{\infty} (x - \mu)^2 \cdot f(x) \, dx\), where \(f(x)\) is the probability density function of \(X\).</p>
            <p>Applying Markov's inequality to the non-negative random variable \((X - \mu)^2\), we obtain:</p>
            <p>\(P((X - \mu)^2 \geq k^2\sigma^2) \leq \frac{{\mathbb{E}[(X - \mu)^2]}}{{k^2\sigma^2}} = \frac{{\text{Var}(X)}}{{k^2\sigma^2}} = \frac{{1}}{{k^2}}\).</p>
            <p>Simplifying the inequality, we get \(P(|X - \mu| \geq k\sigma) \leq \frac{{1}}{{k^2}}\), which proves Chebyshev's inequality.</p>
          </div>
          
          <li><strong>Hoeffding's Inequality:</strong> Hoeffding's inequality is used to bound the deviation of the sum of independent and bounded random variables from its expected value. Let \(X_1, X_2, \ldots, X_n\) be independent random variables bounded between \(a_i\) and \(b_i\), and let \(S_n = X_1 + X_2 + \ldots + X_n\) be their sum. Hoeffding's inequality states that for any \(\epsilon > 0\), \(P(S_n - \mathbb{E}[S_n] \geq \epsilon) \leq e^{-2\epsilon^2 / \sum_{i=1}^{n}(b_i - a_i)^2}\).</li>
          
          <div class="proof">
            <h4>Proof:</h4>
            <p>The proof of Hoeffding's inequality involves applying Chernoff's method. It relies on the fact that the moment-generating function of a bounded random variable \(X\) is finite.</p>
            <p>Using the definition of the moment-generating function (MGF) \(M_X(t)\), we have \(M_X(t) = \mathbb{E}[e^{tX}]\).</p>
            <p>By applying Markov's inequality to the MGF, we obtain:</p>
            <p>\(P(S_n - \mathbb{E}[S_n] \geq \epsilon) = P(e^{t(S_n - \mathbb{E}[S_n])} \geq e^{t\epsilon}) \leq \frac{{\mathbb{E}[e^{t(S_n - \mathbb{E}[S_n])}]}}{{e^{t\epsilon}}}\).</p>
            <p>By using the independence of \(X_1, X_2, \ldots, X_n\) and the MGF properties, we can simplify the above expression as:</p>
            <p>\(\frac{{\mathbb{E}[e^{tX_1}] \cdot \mathbb{E}[e^{tX_2}] \cdots \mathbb{E}[e^{tX_n}]}}{{e^{t\epsilon}}}\).</p>
            <p>By applying the boundedness condition on the random variables, we have \(e^{tX_i} \leq e^{t(b_i - a_i)}\) for each \(i\).</p>
            <p>Using the independence property and the boundedness condition, we can further simplify the expression:</p>
            <p>\(\frac{{e^{t(b_1 - a_1)} \cdot e^{t(b_2 - a_2)} \cdots e^{t(b_n - a_n)}}}{{e^{t\epsilon}}}\).</p>
            <p>Summing up the terms and applying logarithm properties, we get:</p>
            <p>\(\log\left(\frac{{e^{t(b_1 - a_1)} \cdot e^{t(b_2 - a_2)} \cdots e^{t(b_n - a_n)}}}{{e^{t\epsilon}}}\right) = t\sum_{i=1}^{n}(b_i - a_i) - t\epsilon\).</p>
            <p>By rearranging the terms and applying the exponential function, we obtain:</p>
            <p>\(\frac{{\mathbb{E}[e^{t(S_n - \mathbb{E}[S_n])}]}}{{e^{t\epsilon}}} \leq e^{t\sum_{i=1}^{n}(b_i - a_i) - t\epsilon}\).</p>
            <p>To minimize the right-hand side, we choose the optimal value of \(t = \frac{{\epsilon}}{{2\sum_{i=1}^{n}(b_i - a_i)}}\). Substituting this value, we get:</p>
            <p>\(P(S_n - \mathbb{E}[S_n] \geq \epsilon) \leq e^{-2\epsilon^2 / \sum_{i=1}^{n}(b_i - a_i)^2}\).</p>
            <p>This completes the proof of Hoeffding's inequality.</p>
          </div>
          
          <li><strong>Chernoff Bound:</strong> Chernoff bound provides exponential tail bounds on the sum of independent random variables using moment-generating functions. Let \(X_1, X_2, \ldots, X_n\) be independent random variables, and let \(S_n = X_1 + X_2 + \ldots + X_n\) be their sum. For any \(t > 0\), Chernoff bound states that \(P(S_n \geq t) \leq e^{-t}\prod_{i=1}^{n}M_{X_i}(t)\), where \(M_{X_i}(t)\) is the moment-generating function of \(X_i\).</li>
          
          <div class="proof">
            <h4>Proof:</h4>
            <p>The proof of Chernoff bound involves applying the exponential Markov's inequality.</p>
            <p>Using the definition of the moment-generating function (MGF) \(M_X(t)\), we have \(M_X(t) = \mathbb{E}[e^{tX}]\).</p>
            <p>By applying Markov's inequality to the MGF, we obtain:</p>
            <p>\(P(S_n \geq t) = P(e^{tS_n} \geq e^{t}) \leq \frac{{\mathbb{E}[e^{tS_n}]}}{{e^{t}}}\).</p>
            <p>Using the independence of \(X_1, X_2, \ldots, X_n\) and the MGF properties, we can simplify the above expression as:</p>
            <p>\(\frac{{\mathbb{E}[e^{tX_1}] \cdot \mathbb{E}[e^{tX_2}] \cdots \mathbb{E}[e^{tX_n}]}}{{e^{t}}}\).</p>
            <p>By applying the definition of the MGF, this further simplifies to:</p>
            <p>\(\frac{{M_{X_1}(t) \cdot M_{X_2}(t) \cdots M_{X_n}(t)}}{{e^{t}}}\).</p>
            <p>Applying logarithm properties, we can rewrite the expression as:</p>
            <p>\(\log\left(\frac{{M_{X_1}(t) \cdot M_{X_2}(t) \cdots M_{X_n}(t)}}{{e^{t}}}\right) = \sum_{i=1}^{n}\log(M_{X_i}(t)) - t\).</p>
            <p>By rearranging the terms and applying the exponential function, we obtain:</p>
            <p>\(\frac{{\mathbb{E}[e^{tS_n}]}}{{e^{t}}} \leq e^{\sum_{i=1}^{n}\log(M_{X_i}(t)) - t}\).</p>
            <p>To minimize the right-hand side, we choose the optimal value of \(t\) that maximizes the exponent term. Taking the derivative with respect to \(t\) and setting it to zero, we find the optimal \(t\) that maximizes the exponent term.</p>
            <p>Substituting this optimal value of \(t\) back into the inequality, we get:</p>
            <p>\(P(S_n \geq t) \leq e^{-t}\prod_{i=1}^{n}M_{X_i}(t)\).</p>
            <p>This completes the proof of Chernoff bound.</p>
          </div>
          
          <li><strong>Concentration Bounds for Martingales:</strong> Concentration bounds for martingales are specialized concentration inequalities used to analyze sequences of random variables. They provide bounds on the deviations of martingale differences, which are central to understanding the behavior of dynamic stochastic processes.</li>
        </ul>
        
        <h3>Applications of Concentration Inequalities</h3>
        <p>Concentration inequalities find applications in various fields, enabling researchers and practitioners to reason about the behavior of random phenomena:</p>
        
        <ul>
          <li><strong>Probabilistic Analysis of Algorithms:</strong> Concentration inequalities are used to analyze the performance of randomized algorithms and provide bounds on their running time, error probabilities, or approximation guarantees. They help establish probabilistic guarantees on the behavior of algorithms, even when faced with uncertain or random inputs.</li>
          <li><strong>Statistical Estimation:</strong> Concentration inequalities play a crucial role in statistical estimation. They help analyze the quality and accuracy of estimators, such as sample mean or sample variance, and provide confidence intervals. Concentration inequalities allow us to quantify the precision of estimates and assess the probability of significant deviations from the true population values.</li>
          <li><strong>Machine Learning:</strong> Concentration inequalities have significant implications for machine learning. They are used to analyze the generalization error of learning algorithms and establish bounds on their performance. By bounding the deviation of training error from test error, concentration inequalities help reason about the ability of machine learning models to generalize to unseen data.</li>
          <li><strong>Large Deviation Theory:</strong> Concentration inequalities are central to large deviation theory, which studies the probabilities of rare events occurring in complex systems. By providing exponential tail bounds, concentration inequalities enable the analysis of the extreme behavior of random variables and capture the likelihood of observing rare or atypical events in various scientific and engineering domains.</li>
        </ul>
        
        <h3>Conclusion</h3>
        <p>Concentration inequalities offer powerful tools for understanding the behavior of random variables and establishing probabilistic guarantees. By bounding the deviation of random variables from their expected values, concentration inequalities provide insights into the concentration or tightness of probability distributions. Whether in algorithm analysis, statistical estimation, machine learning, or large deviation theory, concentration inequalities enable researchers and practitioners to reason about the behavior of random phenomena and make informed decisions based on probabilistic guarantees.</p>
        
        <p>Explore the applications of concentration inequalities in your own field and harness their potential to gain deeper insights into random processes and phenomena.</p>
        
        <h3>References</h3>
        <ul>
          <li>Boucheron, S., Lugosi, G., & Massart, P. (2013). Concentration Inequalities: A Nonasymptotic Theory of Independence. Oxford University Press.</li>
          <li>Wainwright, M. J. (2019). High-Dimensional Statistics: A Non-Asymptotic Viewpoint. Cambridge University Press.</li>
          <li>Vershynin, R. (2018). High-Dimensional Probability: An Introduction with Applications in Data Science. Cambridge University Press.</li>
        </ul>

        </div>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="modal-blog2" tabindex="-1" aria-hidden="true"
>
  <div class="modal-dialog modal-dialog-scrollable">
    <div class="modal-content">
      <div class="modal-header">
        <h1 class="modal-title fs-5" id="staticBackdropLabel">
          Unraveling Patterns Over Time: An Introduction to Time Series Analysis
        </h1>
        <button
          type="button"
          class="btn-close"
          data-bs-dismiss="modal"
          aria-label="Close"
        ></button>
      </div>
      <div class="modal-body">
        <div class="d-flex flex-column gap-2">
        
        <p>Time series analysis is a powerful tool for understanding and forecasting data that evolves over time. From stock prices and weather patterns to economic indicators and social media trends, time series data can provide valuable insights into underlying patterns and trends. In this blog post, we will explore the fundamentals of time series analysis, key concepts, and popular modeling techniques to help you make sense of time-dependent data.</p>

        <h3>What is a Time Series?</h3>
        <p>A time series is a sequence of data points collected at regular intervals over time. It could be daily stock prices, monthly sales figures, or hourly temperature readings. The key characteristic of time series data is its temporal ordering, where each observation is influenced by previous values and potentially exhibits trends, seasonality, and other time-dependent patterns.</p>

        <h3>Key Concepts in Time Series Analysis</h3>
        <h4>Trend Analysis</h4>
        <p>Trends represent the long-term movement of a time series. They can be upward, indicating growth, or downward, suggesting a decline. Identifying trends is crucial for understanding underlying patterns and making predictions.</p>

        <h4>Seasonality and Periodicity</h4>
        <p>Seasonality refers to patterns that repeat at fixed intervals, such as weekly, monthly, or yearly cycles. Identifying and modeling seasonality is essential to capture recurring patterns and make accurate forecasts.</p>

        <h4>Stationarity</h4>
        <p>A stationary time series exhibits constant mean (\(\mu\)), variance (\(\sigma^2\)), and autocovariance (\(\gamma\)) over time. Formally, a time series \(\{X_t\}\) is stationary if it satisfies the following conditions:</p>

        <ul>
          <li>Constant mean: \(E(X_t) = \mu\) for all \(t\).</li>
          <li>Constant variance: \(Var(X_t) = \sigma^2\) for all \(t\).</li>
          <li>Constant autocovariance: \(Cov(X_t, X_{t+k}) = \gamma(k)\) for all \(t\) and a lag \(k\).</li>
        </ul>

        <p>Stationarity simplifies analysis by making patterns easier to interpret and model. Techniques like differencing can be applied to transform non-stationary data into stationary.</p>

        <h4>Autocorrelation</h4>
        <p>Autocorrelation measures the correlation between a time series and its lagged values. Understanding autocorrelation helps identify patterns and dependencies between past and current observations.</p>
        
        <h4>Time Series Decomposition</h4>
        <p>Decomposing a time series separates it into its constituent components: trend, seasonality, and residuals (random fluctuations). The additive decomposition model expresses a time series \(Y_t\) as the sum of its trend (\(T_t\)), seasonal component (\(S_t\)), and residuals (\(R_t\)):</p>
        
        <p>\[Y_t = T_t + S_t + R_t\]</p>
        
        <p>The multiplicative decomposition model expresses the time series as the product of its components:</p>
        
        <p>\[Y_t = T_t \times S_t \times R_t\]</p>
        
        <p>Decomposition provides insights into individual patterns and helps analyze their contributions to the overall time series behavior.</p>
        
        <h3>Time Series Models</h3>
        
        <h4>Moving Average (MA) Models</h4>
        <p>MA models capture short-term dependencies in a time series using a moving average of past observations. An MA(q) model is defined as:</p>
        
        <p>\[X_t = \mu + \varepsilon_t + \theta_1\varepsilon_{t-1} + \theta_2\varepsilon_{t-2} + \ldots + \theta_q\varepsilon_{t-q}\]</p>
        
        <p>where \(X_t\) is the observed value at time \(t\), \(\mu\) is the mean, \(\varepsilon_t\) is the white noise error term, and \(\theta_1, \theta_2, \ldots, \theta_q\) are the parameters of the model.</p>
        
        <h4>Autoregressive (AR) Models</h4>
        <p>AR models capture the relationship between a time series and its past values. An AR(p) model of order \(p\) is defined as:</p>
        
        <p>\[X_t = \phi_0 + \phi_1X_{t-1} + \phi_2X_{t-2} + \ldots + \phi_pX_{t-p} + \varepsilon_t\]</p>
        
        <p>where \(\phi_0, \phi_1, \ldots, \phi_p\) are the parameters of the model.</p>
        
        <h4>Autoregressive Moving Average (ARMA) Models</h4>
        <p>ARMA models combine the features of MA and AR models. An ARMA(p, q) model is defined as:</p>
        
        <p>\[X_t = \phi_0 + \phi_1X_{t-1} + \phi_2X_{t-2} + \ldots + \phi_pX_{t-p} + \varepsilon_t + \theta_1\varepsilon_{t-1} + \theta_2\varepsilon_{t-2} + \ldots + \theta_q\varepsilon_{t-q}\]</p>
        
        <p>where \(\phi_0, \phi_1, \ldots, \phi_p\) and \(\theta_1, \theta_2, \ldots, \theta_q\) are the parameters of the model.</p>
        
        <h4>Autoregressive Integrated Moving Average (ARIMA) Models</h4>
        <p>ARIMA models handle non-stationary time series by differencing them to achieve stationarity. An ARIMA(p, d, q) model is defined as:</p>
        
        <p>\[\Delta^dX_t = \phi_0 + \phi_1\Delta^dX_{t-1} + \phi_2\Delta^dX_{t-2} + \ldots + \phi_p\Delta^dX_{t-p} + \varepsilon_t + \theta_1\varepsilon_{t-1} + \theta_2\varepsilon_{t-2} + \ldots + \theta_q\varepsilon_{t-q}\]</p>
        
        <p>where \(\Delta^dX_t\) represents the differencing of order \(d\) of the time series.</p>
        
        <h3>Forecasting with Time Series Analysis</h3>
        
        <p>Forecasting involves predicting future values based on historical patterns. Techniques like simple moving average, exponential smoothing, and ARIMA-based forecasting are commonly used for time series forecasting. These methods help anticipate future trends, make informed decisions, and plan effectively.</p>
        
        <h3>Conclusion</h3>
        
        <p>Time series analysis empowers us to unravel hidden patterns and make accurate predictions in time-dependent data. By understanding concepts like trends, seasonality, stationarity, and using models like AR, MA, ARMA, and ARIMA, we can gain valuable insights and make informed decisions based on historical patterns. Whether you're analyzing financial data, weather patterns, or customer behavior, mastering time series analysis opens up a world of possibilities for data-driven decision-making.</p>
        
        <p>Take the time to explore time series analysis further, experiment with different techniques, and apply them to your own data. With practice, you'll become adept at uncovering the secrets hidden within the flow of time.</p>
        
        <h3>References</h3>
        
        <ul>
          <li>Hyndman, R.J., & Athanasopoulos, G. (2018). Forecasting: Principles and Practice. OTexts: Melbourne, Australia.</li>
          <li>Brockwell, P.J., & Davis, R.A. (2016). Introduction to Time Series and Forecasting. Springer.</li>
        </ul>

        </div>
      </div>
    </div>
  </div>
</div>

<div class="modal fade" id="modal-blog3" tabindex="-1" aria-hidden="true"
>
  <div class="modal-dialog modal-dialog-scrollable">
    <div class="modal-content">
      <div class="modal-header">
        <h1 class="modal-title fs-5" id="staticBackdropLabel">
          Biased Coin Simulation
        </h1>
        <button
          type="button"
          class="btn-close"
          data-bs-dismiss="modal"
          aria-label="Close"
        ></button>
      </div>
      <div class="modal-body">
        <div class="d-flex flex-column gap-2">
          <p>
            A question I used to give in interviews was the following:
          </p>

          <p>
            I have a fair coin. How can I simulate a 1/3 probability of obtaining heads using a fair coin?
          </p>

          <p>
            Well today I'm going to discuss two solutions in detail.
          </p>

          <p>
            Flipping a coin is a classic random experiment that often leads to a 50/50 chance of getting heads or tails. However, what if we want to simulate a different probability, such as a 1/3 chance of getting heads? In this blog post, we will explore a simple technique to achieve this using a fair coin. So, let's get started!
          </p>

          <p>
            People usually give a solution along the lines of "flip the coin twice and see if you get 'HH'. If you see a 'TT', then skip and flip again." This may work but it requires you to record two consecutive tosses.
          </p>

          <p>
            What is very neat is that there's a solution that only requires knowing the running count of tosses and the most recent toss! Believe it or not, this involves the binary expansion of 1/3:

            <br>
            
            \(\sum_{i=1}^{\infty} \frac{1}{2^{2i}} = \frac{1}{3}.\)

            <br>
            
            By the above identity, we can use the following stopping rule:
            <ol>
            <li>Flip until you see your first heads.</li>
            <li>Assign the outcome based on the number of tosses:
                <ul>
                    <li>If the total number of tosses is even, consider it as "heads".</li>
                    <li>Otherwise, consider it as "tails".</li>
                </ul>
            </li>
            </ol>
            One can see that the probability of obtaining a "heads" here is 1/3.
          </p>

        </div>
      </div>
    </div>
  </div>
</div>